{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import cv2\n",
    "import os"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "def feature_extraction_set(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    kp, des = [], []\n",
    "    for im in images:\n",
    "        kp_tmp, des_tmp = sift.detectAndCompute(im, None) # This assumes the extraction method to be from the CV2 library\n",
    "        kp.append(kp_tmp)\n",
    "        des.append(des_tmp)\n",
    "    return kp, des # Can't turn them into a np array since their shape can be inhomogeneous"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def feature_matching_set(kp, des):\n",
    "    # Initialize FLANN matching\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = {} # Dict for easier access to each match\n",
    "    for i in range(len(kp)):\n",
    "        for j in range(i+1, len(kp)): # Only match each image with the rest, we don't need the full matrix\n",
    "            matches_tmp = flann.knnMatch(des[i], des[j], k=2)\n",
    "\n",
    "            # Lowe's ratio test\n",
    "            good_matches = [m for m, n in matches_tmp if m.distance < 0.7 * n.distance]\n",
    "\n",
    "            if len(good_matches) >= 4:\n",
    "                # RANSAC to find homography and get inlier's mask\n",
    "                pts1 = np.float32([kp[i][m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                pts2 = np.float32([kp[j][m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                _, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "\n",
    "                inliers = [good_matches[k] for k in range(len(good_matches)) if mask[k]==1]\n",
    "                matches[(i,j)] = inliers\n",
    "            else:\n",
    "                matches[(i,j)] = []\n",
    "    \n",
    "    return matches"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def normalize(pts):\n",
    "    x_mean = np.mean(pts[:, 0])\n",
    "    y_mean = np.mean(pts[:, 1])\n",
    "    sigma = np.mean(np.sqrt((pts[:, 0] - x_mean) ** 2 + (pts[:, 1] - y_mean) ** 2))\n",
    "    M = np.sqrt(2) / sigma\n",
    "    T = np.array([\n",
    "        [M, 0, -M * x_mean],\n",
    "        [0, M, -M * y_mean],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    return T\n",
    "\n",
    "def eight_point_algorithm(pts1, pts2):\n",
    "\n",
    "    pts1_homo = np.vstack((pts1, np.ones(pts1.shape[1]))).T\n",
    "    pts2_homo = np.vstack((pts2, np.ones(pts2.shape[1]))).T\n",
    "\n",
    "    # Normalization\n",
    "    T = normalize(pts1_homo)\n",
    "    T_prime = normalize(pts2_homo)\n",
    "\n",
    "\n",
    "    pts1_homo = (T @ pts1_homo.T).T\n",
    "    pts2_homo = (T_prime @ pts2_homo.T).T\n",
    "\n",
    "    # x2.T*F*x1=0\n",
    "    # A*f=0, f is F flattened into a 1D array\n",
    "    \n",
    "\n",
    "    # Create A\n",
    "    A = np.zeros((pts1.shape[1], 9))\n",
    "    for i in range(pts1.shape[1]):\n",
    "        A[i] = np.array([\n",
    "            pts1_homo[i,0]*pts2_homo[i,0], pts1_homo[i,1]*pts2_homo[i,0], pts1_homo[i,2]*pts2_homo[i,0],\n",
    "            pts1_homo[i,0]*pts2_homo[i,1], pts1_homo[i,1]*pts2_homo[i,1], pts1_homo[i,2]*pts2_homo[i,1],\n",
    "            pts1_homo[i,0]*pts2_homo[i,2], pts1_homo[i,1]*pts2_homo[i,2], pts1_homo[i,2]*pts2_homo[i,2]\n",
    "            ])\n",
    "    \n",
    "    # Solve Af=0 using svd\n",
    "    U,S,Vt = np.linalg.svd(A)\n",
    "    F = Vt[-1,:].reshape((3,3))\n",
    "\n",
    "    # Enforce rank2 constraint\n",
    "    U,S,Vt = np.linalg.svd(F)\n",
    "    S[-1] = 0\n",
    "    F = U @ np.diag(S) @ Vt\n",
    "\n",
    "    F = T_prime.T @ F @ T\n",
    "    return F"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "def essential_from_fundamental(K1, F, K2):\n",
    "    return K1.T @ F @ K2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "def pose_from_essential(R1, T1, E):\n",
    "    U,_,Vt = np.linalg.svd(E)\n",
    "    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "    \n",
    "    # Array with all possible camera poses (extrinsics)\n",
    "    R = np.array([U @ W @ Vt, U @ W.T @ Vt])\n",
    "    T = np.array([U[:, 2], -U[:, 2]])\n",
    "\n",
    "    for i in range(R.shape[0]):\n",
    "        R[i] = R1 @ R[i]\n",
    "        if np.linalg.det(R[i]) < 0:\n",
    "            R[i] = R[i] * -1\n",
    "        T[i] = R1 @ T[i] + T1\n",
    "\n",
    "    return R, T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "def linear_triangulation(K1, RT1, K2, RT2, pts1, pts2):\n",
    "    # First, set all points to homogeneous\n",
    "    pts1_homo = np.vstack((pts1, np.ones(pts1.shape[1])))\n",
    "    pts2_homo = np.vstack((pts2, np.ones(pts2.shape[1])))\n",
    "\n",
    "    # Calculate every projection matrix\n",
    "    P1 = K1 @ RT1\n",
    "    P2 = K2 @ RT2\n",
    "\n",
    "    # Solve using svd\n",
    "    pts3d = np.zeros((3, pts1.shape[1]))\n",
    "    for i in range(pts1.shape[1]):\n",
    "        A = np.array([pts1_homo[1,i]*P1[2,:] - P1[1,:],\n",
    "            P1[0,:] - pts1_homo[0,i]*P1[2,:],\n",
    "            pts2_homo[1,i]*P2[2,:] - P2[1,:],\n",
    "            P2[0,:] - pts2_homo[0,i]*P2[2,:]])\n",
    "        ATA = A.T @ A\n",
    "        _, _, Vt = np.linalg.svd(ATA)\n",
    "        pts3d[:, i] = Vt[-1, :3]/Vt[-1, -1]\n",
    "    \n",
    "    return pts3d\n",
    "\n",
    "def linear_triangulation2(P1, P2, pts1, pts2):\n",
    "    # First, set all points to homogeneous\n",
    "    pts1_homo = np.vstack((pts1, np.ones(pts1.shape[1])))\n",
    "    pts2_homo = np.vstack((pts2, np.ones(pts2.shape[1])))\n",
    "\n",
    "    # Solve using svd\n",
    "    pts3d = np.zeros((3, pts1.shape[1]))\n",
    "    for i in range(pts1.shape[1]):\n",
    "        A = np.array([pts1_homo[1,i]*P1[2,:] - P1[1,:],\n",
    "                      P1[0,:] - pts1_homo[0,i]*P1[2,:],\n",
    "                      pts2_homo[1,i]*P2[2,:] - P2[1,:],\n",
    "                      P2[0,:] - pts2_homo[0,i]*P2[2,:]])\n",
    "        ATA = A.T @ A\n",
    "        _, _, Vt = np.linalg.svd(ATA)\n",
    "        pts3d[:, i] = Vt[-1, :3]/Vt[-1, -1]\n",
    "    \n",
    "    return pts3d\n",
    "\n",
    "def linear_triangulation3(K1, R1, T1, K2, R2, T2, pts1, pts2):\n",
    "    # First, set all points to homogeneous\n",
    "    pts1_homo = np.vstack((pts1, np.ones(pts1.shape[1])))\n",
    "    pts2_homo = np.vstack((pts2, np.ones(pts2.shape[1])))\n",
    "\n",
    "    # Calculate every projection matrix\n",
    "    P1 = K1 @ np.hstack((R1, T1[:, np.newaxis]))\n",
    "    P2 = K2 @ np.hstack((R2, T2[:, np.newaxis]))\n",
    "\n",
    "    # Solve using svd\n",
    "    pts3d = np.zeros((3, pts1.shape[1]))\n",
    "    for i in range(pts1.shape[1]):\n",
    "        A = np.array([pts1_homo[1,i]*P1[2,:] - P1[1,:],\n",
    "            P1[0,:] - pts1_homo[0,i]*P1[2,:],\n",
    "            pts2_homo[1,i]*P2[2,:] - P2[1,:],\n",
    "            P2[0,:] - pts2_homo[0,i]*P2[2,:]])\n",
    "        ATA = A.T @ A\n",
    "        _, _, Vt = np.linalg.svd(ATA)\n",
    "        pts3d[:, i] = Vt[-1, :3]/Vt[-1, -1]\n",
    "    \n",
    "    return pts3d"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "def reprojection(P1, P2, pts3d):\n",
    "    pts3d_homo = np.vstack((pts3d, np.ones(pts3d.shape[1])))\n",
    "    pts2d1_homo = np.dot(P1, pts3d_homo)\n",
    "    pts2d2_homo = np.dot(P2, pts3d_homo)\n",
    "    return pts2d1_homo/pts2d1_homo[-1], pts2d2_homo/pts2d2_homo[-1]\n",
    "\n",
    "def double_disambiguation(K1, RT1, K2, RT2s, pts1, pts2, pts3d):\n",
    "    max_positive_z = 0\n",
    "    min_error = np.finfo('float').max\n",
    "    best_RT = None\n",
    "    best_pts3d = None\n",
    "    P1 = K1 @ RT1\n",
    "\n",
    "    pts1_homo = np.vstack((pts1, np.ones(pts1.shape[1])))\n",
    "    pts2_homo = np.vstack((pts2, np.ones(pts2.shape[1])))\n",
    "\n",
    "    for i in range(RT2s.shape[0]):\n",
    "        P2 = K2 @ RT2s[i]\n",
    "        num_positive_z = np.sum(pts3d[i][2, :] > 0)\n",
    "        re1_pts2, re2_pts2 = reprojection(P1, P2, pts3d[i])\n",
    "\n",
    "        err1 = np.sum(np.square(re1_pts2 - pts1_homo))\n",
    "        err2 = np.sum(np.square(re2_pts2 - pts2_homo))\n",
    "\n",
    "        err = err1 + err2\n",
    "\n",
    "        if num_positive_z >= max_positive_z and err < min_error:\n",
    "            max_positive_z = num_positive_z\n",
    "            min_error = err\n",
    "            best_RT = RT2s[i]\n",
    "            best_pts3d = pts3d[i]\n",
    "    \n",
    "    return best_RT, best_pts3d\n",
    "\n",
    "def double_disambiguation2(K1, R1, T1, K2, R2s, T2s, pts1, pts2, pts3d):\n",
    "    max_positive_z = 0\n",
    "    min_error = np.finfo('float').max\n",
    "    best_R = None\n",
    "    best_T = None\n",
    "    best_pts3d = None\n",
    "    P1 = K1 @ np.hstack((R1, T1[:, np.newaxis]))\n",
    "\n",
    "    pts1_homo = np.vstack((pts1, np.ones(pts1.shape[1])))\n",
    "    pts2_homo = np.vstack((pts2, np.ones(pts2.shape[1])))\n",
    "\n",
    "    for i in range(R2s.shape[0]):\n",
    "        P2 = K2 @ np.hstack((R2s[i], T2s[i, :, np.newaxis]))\n",
    "        \n",
    "        pts3d_cam2 = np.dot(np.linalg.inv(R2s[i]), pts3d[i] - T2s[i, :, np.newaxis])\n",
    "\n",
    "        num_positive_z = np.sum(pts3d_cam2[2, :] > 0)\n",
    "        re1_pts2, re2_pts2 = reprojection(P1, P2, pts3d[i])\n",
    "\n",
    "        err1 = np.sum(np.square(re1_pts2 - pts1_homo))\n",
    "        err2 = np.sum(np.square(re2_pts2 - pts2_homo))\n",
    "\n",
    "        err = err1 + err2\n",
    "\n",
    "        if num_positive_z >= max_positive_z and err < min_error:\n",
    "            max_positive_z = num_positive_z\n",
    "            min_error = err\n",
    "            best_R = R2s[i]\n",
    "            best_T = T2s[i]\n",
    "            best_pts3d = pts3d[i]\n",
    "    \n",
    "    return best_R, best_T, best_pts3d"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Two Images SfM\n",
    "\n",
    "We're following the \"guide\" provided by this [GitHub's README by rohana96](https://github.com/rohana96/SfM), following an incremental SfM. However, we tried to make the different steps by ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous feature extraction and matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# Load all images\n",
    "images = np.array(load_images_from_folder('dinos'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# Intrinsic values of camera (assume all images were taken with the same camera)\n",
    "# K = np.loadtxt('intrinsic_matrix.txt', dtype=float)\n",
    "\n",
    "height, width = images.shape[1:3]\n",
    "K = np.array([  # for dino\n",
    "    [2360, 0, width / 2],\n",
    "    [0, 2360, height / 2],\n",
    "    [0, 0, 1]])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# Initialize Projection matrix list\n",
    "P_list = [K @ np.hstack((np.eye(3), np.zeros((3, 1))))]\n",
    "R_list = [np.eye(3)]\n",
    "T_list = [np.zeros(3)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "RT = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "RT_homo = np.vstack((RT, np.array([0, 0, 0, 1])))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# Initialize 3D point cloud\n",
    "pts3d_cloud = None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "# Feature extraction and matching\n",
    "kp, des = feature_extraction_set(images[:3])\n",
    "\n",
    "matches = feature_matching_set(kp, des)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "# Main for loop\n",
    "for i in range(1, 3):\n",
    "\n",
    "    # Define points for this iteration\n",
    "    pts1 = np.transpose([kp[i-1][m.queryIdx].pt for m in matches[(i-1,i)]])\n",
    "    pts2 = np.transpose([kp[i][m.trainIdx].pt for m in matches[(i-1,i)]])\n",
    "\n",
    "    # Get Fundamental matrix from i - 1\n",
    "    F = eight_point_algorithm(pts1, pts2)\n",
    "\n",
    "    # Get Essential matrix from F\n",
    "    E = essential_from_fundamental(K, F, K)\n",
    "\n",
    "    # Get camera extrinsics from Essential\n",
    "    R_set, T_set = pose_from_essential(R_list[i-1], T_list[i-1], E)\n",
    "\n",
    "    # Possible triangulations\n",
    "    pts3d = np.array([linear_triangulation3(K, R_list[i-1], T_list[i-1], K, R, T, pts1, pts2) for R in R_set for T in T_set])\n",
    "\n",
    "    # Disambiguation\n",
    "    R, T, pts3d = double_disambiguation2(K, R_list[i-1], T_list[i-1], K, R_set, T_set, pts1, pts2, pts3d)\n",
    "\n",
    "    # Add R, T and pts3d to their respective lists\n",
    "    P_list.append(K @ np.hstack((R, T[:, np.newaxis])))\n",
    "    R_list.append(R)\n",
    "    T_list.append(T)\n",
    "    if isinstance(pts3d_cloud, np.ndarray):\n",
    "        pts3d_cloud = np.hstack((pts3d_cloud, pts3d))\n",
    "    else:\n",
    "        pts3d_cloud = np.array(pts3d)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "# for i in range(1, 5):\n",
    "#     pts1 = np.transpose([kp[i-1][m.queryIdx].pt for m in matches[(i-1,i)]])\n",
    "#     pts2 = np.transpose([kp[i][m.trainIdx].pt for m in matches[(i-1,i)]])\n",
    "#     pts3d = linear_triangulation2(P_list[i-1], P_list[i], pts1, pts2)\n",
    "\n",
    "#     if isinstance(pts3d_cloud, np.ndarray):\n",
    "#         pts3d_cloud = np.hstack((pts3d_cloud, pts3d))\n",
    "#     else:\n",
    "#         pts3d_cloud = np.array(pts3d)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "# Visualize Cameras\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_transforms(transforms):\n",
    "    # Create a 3D figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Create the unit vectors\n",
    "    i = np.array([1, 0, 0])\n",
    "    j = np.array([0, 1, 0])\n",
    "    k = np.array([0, 0, 1])\n",
    "\n",
    "    for idx, transform in enumerate(transforms):\n",
    "        R, T = transform\n",
    "\n",
    "        # Apply the rotation matrix to the unit vectors\n",
    "        i_prime = R @ i\n",
    "        j_prime = R @ j\n",
    "        k_prime = R @ k\n",
    "\n",
    "        # Plot the new coordinate system\n",
    "        fig.add_trace(go.Cone(x=[T[0]], y=[T[1]], z=[T[2]], u=[i_prime[0]], v=[i_prime[1]], w=[i_prime[2]], sizemode=\"scaled\", sizeref=0.2, name='i'))\n",
    "        fig.add_trace(go.Cone(x=[T[0]], y=[T[1]], z=[T[2]], u=[j_prime[0]], v=[j_prime[1]], w=[j_prime[2]], sizemode=\"scaled\", sizeref=0.2, name='j'))\n",
    "        fig.add_trace(go.Cone(x=[T[0]], y=[T[1]], z=[T[2]], u=[k_prime[0]], v=[k_prime[1]], w=[k_prime[2]], sizemode=\"scaled\", sizeref=0.2, name='k'))\n",
    "\n",
    "    fig.update_layout(scene=dict(aspectmode='data'))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_transforms(zip(R_list, T_list))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "# Visualize 3D points\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming points_3D is your array of 3D points\n",
    "x = pts3d_cloud[0]\n",
    "y = pts3d_cloud[1]\n",
    "z = pts3d_cloud[2]\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z,\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(size=2, color=z, colorscale='Viridis'))])\n",
    "\n",
    "fig.update_layout(scene=dict(xaxis_title='X',\n",
    "                             yaxis_title='Y',\n",
    "                             zaxis_title='Z'))\n",
    "\n",
    "fig.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
