{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import cv2\n",
    "import os"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "images = np.array(load_images_from_folder('dinos'))[0:2]\n",
    "cv2.imshow('window', images[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "K = np.loadtxt(\"intrinsic_matrix.txt\", dtype=float)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "# height, width, ch = images.shape[1:4]\n",
    "# K = np.array([  # for dino\n",
    "#     [2360, 0, width / 2],\n",
    "#     [0, 2360, height / 2],\n",
    "#     [0, 0, 1]])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "# def load_data(path='cameras'):\n",
    "\n",
    "#     C1 = np.load(f'{path}/cam1.npz')\n",
    "#     C2 = np.load(f'{path}/cam2.npz')\n",
    "#     K1 = C1['K']\n",
    "#     K2 = C2['K']\n",
    "\n",
    "#     return K1\n",
    "\n",
    "# K = load_data()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "orb = cv2.SIFT_create()\n",
    "\n",
    "kp, des = [], []\n",
    "for im in images:\n",
    "    kp_tmp, des_tmp = orb.detectAndCompute(im, None)\n",
    "    kp.append(kp_tmp)\n",
    "    des.append(des_tmp)\n",
    "print(len(kp[0])) #kp.shape = n_images x n_keypoints\n",
    "print(des[0].shape) #des.shape = n_images x n_keypoints x descriptor_size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "# Inicializar el emparejador FLANN\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = {}\n",
    "# Comparar cada imagen con todas las demás\n",
    "for i in range(len(images)):\n",
    "    for j in range(i+1, len(images)):\n",
    "        # Emparejar descriptores\n",
    "        matches_tmp = flann.knnMatch(des[i], des[j], k=2)\n",
    "\n",
    "        # Aplicar la prueba de ratio para encontrar buenos emparejamientos (prueba de ratio de Lowe)\n",
    "        good_matches = [m for m, n in matches_tmp if m.distance < 0.7 * n.distance]\n",
    "\n",
    "        # Comprobar si hay suficientes buenos emparejamientos\n",
    "        if len(good_matches) >= 4:\n",
    "            # Aplicar RANSAC para encontrar la matriz de homografía y obtener la máscara de inliers\n",
    "            src_pts = np.float32([kp[i][m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp[j][m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "            # Obtener solo los inliers\n",
    "            inliers = [good_matches[k] for k in range(len(good_matches)) if mask[k]==1]\n",
    "            matches[(i,j)] = inliers\n",
    "            \n",
    "            # Ahora la variable 'inliers' contiene solo los emparejamientos inliers\n",
    "            print(f'Número de inliers: {len(inliers)}')\n",
    "        else:\n",
    "            matches[(i,j)] = []\n",
    "            print(f\"No hay suficientes buenos emparejamientos entre las imágenes para calcular la homografía.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "pts1 = np.array([kp[0][m.queryIdx].pt for m in matches[(0,1)]]).T\n",
    "pts2 = np.array([kp[1][m.trainIdx].pt for m in matches[(0,1)]]).T\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].autoscale_view('tight')\n",
    "ax[0].imshow(cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB))\n",
    "ax[0].plot(pts1[0], pts1[1], 'r.')\n",
    "ax[1].autoscale_view('tight')\n",
    "ax[1].imshow(cv2.cvtColor(images[1], cv2.COLOR_BGR2RGB))\n",
    "ax[1].plot(pts2[0], pts2[1], 'r.')\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "# Fundamental Matrix\n",
    "\n",
    "def normalize_points(pts):\n",
    "    centroid = np.mean(pts, axis=0)\n",
    "    pts = pts-centroid\n",
    "    scale=np.sqrt(2)/np.mean(np.sqrt(np.sum(pts**2, axis=1)))\n",
    "    pts = pts * scale\n",
    "    T = np.array([[scale, 0, -scale*centroid[0]], [0, scale, -scale*centroid[1]], [0, 0, 1]])\n",
    "    return pts, T\n",
    "\n",
    "def eight_point_algorithm(pts1, pts2):\n",
    "    # Normalize the points\n",
    "    pts1, T1 = normalize_points(pts1)\n",
    "    pts2, T2 = normalize_points(pts2)\n",
    "\n",
    "    # Create constraint matrix A (Af=0), each A element is [(xi, xi),(xi)\n",
    "    A = np.zeros((len(pts1), 9))\n",
    "    for i in range(len(pts1)):\n",
    "        A[i] = [pts1[i,0]*pts2[i,0], pts1[i,1]*pts2[i,0], 1*pts2[i,0],\n",
    "                pts1[i,0]*pts2[i,1], pts1[i,1]*pts2[i,1], 1*pts2[i,1],\n",
    "                pts1[i,0]*1,            pts1[i,1]*2,         1*1]\n",
    "    \n",
    "    # f is equal to last column of V from svd of A\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    F = np.reshape(V[-1], (3, 3))\n",
    "\n",
    "    # Enforce rank 2 constraint F=U * diag(S) * V.T\n",
    "    U, S, V = np.linalg.svd(F)\n",
    "    S[-1] = 0\n",
    "    F = U @ np.diag(S) @ V.T\n",
    "\n",
    "    return F\n",
    "\n",
    "fundamental_matrices = []\n",
    "for i in range(len(kp) - 1):\n",
    "    pts1 = np.array([kp[i][m.queryIdx].pt for m in matches[(i,i+1)]])\n",
    "    pts2 = np.array([kp[i+1][m.trainIdx].pt for m in matches[(i,i+1)]])\n",
    "    F = eight_point_algorithm(pts1, pts2)\n",
    "    fundamental_matrices.append(F)\n",
    "fundamental_matrices = np.array(fundamental_matrices) # fundamental_matrices.shape = n_images-1[skipped first image] x (3x3 -> F matrix)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "# Essential matrix\n",
    "def essential_from_fundamental(K, F):\n",
    "    return K.T @ F @ K\n",
    "\n",
    "essential_matrices = []\n",
    "for F in fundamental_matrices:\n",
    "    E = essential_from_fundamental(K, F)\n",
    "    essential_matrices.append(E)\n",
    "essential_matrices = np.array(essential_matrices) # essential_matrices.shape = n_images-1[skipping first image] x (3x3 -> E matrix)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "# First camera initializes at world center aligned\n",
    "Ps = np.zeros((images.shape[0], 3, 4))\n",
    "Ps[0] = K @ np.hstack((np.identity(3), np.zeros(3)[:, np.newaxis]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "# Get Rotation and Translation\n",
    "\n",
    "def get_rot_trans(E):\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    m = S[:2].mean()\n",
    "    E = U @ np.array([[m, 0, 0], [0, m, 0], [0, 0, 0]]) @ V\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "\n",
    "    RTs = np.zeros([3, 4, 4])\n",
    "    RTs[:, :, 0] = np.concatenate([U @ W @ V, U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    RTs[:, :, 1] = np.concatenate([U @ W @ V, -U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    RTs[:, :, 2] = np.concatenate([U @ W.T @ V, U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    RTs[:, :, 3] = np.concatenate([U @ W.T @ V, -U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    return RTs\n",
    "\n",
    "rot_trans_list = []\n",
    "for E in essential_matrices:\n",
    "    RTs = get_rot_trans(E)\n",
    "    rot_trans_list.append(RTs)\n",
    "rot_trans_list = np.array(rot_trans_list) # rot_trans_list.shape = n_images - 1 x (3x4 -> [R|t]) x 4 possibilities"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "source": [
    "# Choose matrix that has all points in front and minimizes reprojection loss\n",
    "\n",
    "def triangulate(pts1, pts2, P1, P2):\n",
    "    # Calculate 3D point\n",
    "    pts4D = np.zeros((4, pts1.shape[1]))\n",
    "    pts4D = cv2.triangulatePoints(P1, P2, pts1, pts2, pts4D)\n",
    "    pts4D /= pts4D[-1, :]\n",
    "\n",
    "    # Calculate reprojection error\n",
    "    # First, get reprojections\n",
    "    pts1_reproj = P1 @ pts4D\n",
    "    pts2_reproj = P2 @ pts4D\n",
    "\n",
    "    pts1_reproj /= pts1_reproj[-1, :]\n",
    "    pts2_reproj /= pts2_reproj[-1, :]\n",
    "\n",
    "    # Second, homogenize every point to compare with the reprojection\n",
    "    # pts1 (2xN)\n",
    "    pts1_homo = np.concatenate((pts1, np.ones((1, pts1.shape[1]))), axis=0)\n",
    "    pts2_homo = np.concatenate((pts2, np.ones((1, pts2.shape[1]))), axis=0)\n",
    "\n",
    "    err1 = np.sum(np.square(pts1_reproj - pts1_homo))\n",
    "    err2 = np.sum(np.square(pts2_reproj - pts2_homo))\n",
    "\n",
    "    err = err1 + err2\n",
    "    return pts4D[:3, :], err\n",
    "\n",
    "for i in range(rot_trans_list.shape[0]):\n",
    "    RT = rot_trans_list[i]\n",
    "    best_RT = np.zeros((3, 4))\n",
    "    best_error = np.finfo('float').max\n",
    "    for j in range(RTs.shape[2]):\n",
    "        RT = RTs[:, :, j]\n",
    "        P2_tmp = K @ RT\n",
    "        pts1 = np.array([kp[i][m.queryIdx].pt for m in matches[(i, i+1)]]).astype('float').T\n",
    "        pts2 = np.array([kp[i+1][m.trainIdx].pt for m in matches[(i, i+1)]]).astype('float').T\n",
    "        X, err = triangulate(pts1, pts2, Ps[i], P2_tmp)\n",
    "        if err < best_error and np.all(X[-1, :] >= 0):\n",
    "            best_error = err\n",
    "            P = X\n",
    "            Ps[i+1] = P2_tmp\n",
    "            best_RT = RT\n",
    "\n",
    "Ps = np.array(Ps) # Ps.shape = n_images x (3x4 -> Projection Matrix)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming points_3D is your array of 3D points\n",
    "x = tripoints3d[0]\n",
    "y = tripoints3d[1]\n",
    "z = -tripoints3d[2]\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z,\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(size=2, color=z, colorscale='Viridis'))])\n",
    "\n",
    "fig.update_layout(scene=dict(xaxis_title='X',\n",
    "                             yaxis_title='Y',\n",
    "                             zaxis_title='Z'))\n",
    "\n",
    "fig.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
