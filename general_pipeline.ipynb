{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "images = load_images_from_folder('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.loadtxt('intrinsic_matrix.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(path='cameras'):\n",
    "\n",
    "#     C1 = np.load(f'{path}/cam1.npz')\n",
    "#     C2 = np.load(f'{path}/cam2.npz')\n",
    "#     K1 = C1['K']\n",
    "#     K2 = C2['K']\n",
    "\n",
    "#     return K1\n",
    "\n",
    "# K = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp, des = [], []\n",
    "for im in images:\n",
    "    kp_tmp, des_tmp = orb.detectAndCompute(im, None)\n",
    "    kp.append(kp_tmp)\n",
    "    des.append(des_tmp)\n",
    "kp = np.array(kp) #kp.shape = n_images x n_keypoints\n",
    "des = np.array(des) #des.shape = n_images x n_keypoints x descriptor_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match features\n",
    "matches = []\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "for i in range(des.shape[0] - 1):\n",
    "    matches_tmp = bf.match(des[i], des[i+1])\n",
    "    matches_tmp = sorted(matches_tmp, key = lambda x:x.distance)\n",
    "    matches.append(matches_tmp)\n",
    "\n",
    "# Matches, list of n_images - 1 x num_matching_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental Matrix\n",
    "\n",
    "def normalize_points(pts):\n",
    "    centroid = np.mean(pts, axis=0)\n",
    "    pts = pts-centroid\n",
    "    scale=np.sqrt(2)/np.mean(np.sqrt(np.sum(pts**2, axis=1)))\n",
    "    pts = pts * scale\n",
    "    T = np.array([[scale, 0, -scale*centroid[0]], [0, scale, -scale*centroid[1]], [0, 0, 1]])\n",
    "    return pts, T\n",
    "\n",
    "def eight_point_algorithm(pts1, pts2):\n",
    "    # Normalize the points\n",
    "    pts1, T1 = normalize_points(pts1)\n",
    "    pts2, T2 = normalize_points(pts2)\n",
    "\n",
    "    # Create constraint matrix A (Af=0), each A element is [(xi, xi),(xi)\n",
    "    A = np.zeros((len(pts1), 9))\n",
    "    for i in range(len(pts1)):\n",
    "        A[i] = [pts1[i,0]*pts2[i,0], pts1[i,1]*pts2[i,0], 1*pts2[i,0],\n",
    "                pts1[i,0]*pts2[i,1], pts1[i,1]*pts2[i,1], 1*pts2[i,1],\n",
    "                pts1[i,0]*1,            pts1[i,1]*2,         1*1]\n",
    "    \n",
    "    # f is equal to last column of V from svd of A\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    F = np.reshape(V[-1], (3, 3))\n",
    "\n",
    "    # Enforce rank 2 constraint F=U * diag(S) * V.T\n",
    "    U, S, V = np.linalg.svd(F)\n",
    "    S[-1] = 0\n",
    "    F = U @ np.diag(S) @ V.T\n",
    "\n",
    "    return F\n",
    "\n",
    "fundamental_matrices = []\n",
    "for i in range(kp.shape[0] - 1):\n",
    "    pts1 = np.array([kp[i][m.queryIdx].pt for m in matches[i]])\n",
    "    pts2 = np.array([kp[i+1][m.trainIdx].pt for m in matches[i]])\n",
    "    F = eight_point_algorithm(pts1, pts2)\n",
    "    fundamental_matrices.append(F)\n",
    "fundamental_matrices = np.array(fundamental_matrices) # fundamental_matrices.shape = n_images-1[skipped first image] x (3x3 -> F matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential matrix\n",
    "def essential_from_fundamental(K, F):\n",
    "    return K.T @ F @ K\n",
    "\n",
    "essential_matrices = []\n",
    "for F in fundamental_matrices:\n",
    "    E = essential_from_fundamental(K, F)\n",
    "    essential_matrices.append(E)\n",
    "essential_matrices = np.array(essential_matrices) # essential_matrices.shape = n_images-1[skipping first image] x (3x3 -> E matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First camera initializes at world center aligned\n",
    "Ps = np.zeros((len(images), 3, 4))\n",
    "Ps[0] = K @ np.hstack((np.identity(3), np.zeros(3)[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Rotation and Translation\n",
    "\n",
    "def get_rot_trans(E):\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    m = S[:2].mean()\n",
    "    E = U @ np.array([[m, 0, 0], [0, m, 0], [0, 0, 0]]) @ V\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "\n",
    "    RTs = np.zeros([3, 4, 4])\n",
    "    RTs[:, :, 0] = np.concatenate([U @ W @ V, U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    RTs[:, :, 1] = np.concatenate([U @ W @ V, -U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    RTs[:, :, 2] = np.concatenate([U @ W.T @ V, U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    RTs[:, :, 3] = np.concatenate([U @ W.T @ V, -U[:, 2].reshape([-1, 1]) / abs(U[:, 2]).max()], axis=1)\n",
    "    return RTs\n",
    "\n",
    "rot_trans_list = []\n",
    "for E in essential_matrices:\n",
    "    RTs = get_rot_trans(E)\n",
    "    rot_trans_list.append(RTs)\n",
    "rot_trans_list = np.array(rot_trans_list) # rot_trans_list.shape = n_images - 1 x (3x4 -> [R|t]) x 4 possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:7: RuntimeWarning: divide by zero encountered in divide\n",
      "  pts4D /= pts4D[-1, :]\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  pts4D /= pts4D[-1, :]\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:11: RuntimeWarning: invalid value encountered in matmul\n",
      "  pts1_reproj = P1 @ pts4D\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:12: RuntimeWarning: invalid value encountered in matmul\n",
      "  pts2_reproj = P2 @ pts4D\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:14: RuntimeWarning: divide by zero encountered in divide\n",
      "  pts1_reproj /= pts1_reproj[-1, :]\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  pts1_reproj /= pts1_reproj[-1, :]\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:15: RuntimeWarning: divide by zero encountered in divide\n",
      "  pts2_reproj /= pts2_reproj[-1, :]\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  pts2_reproj /= pts2_reproj[-1, :]\n",
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_8668\\2346666757.py:7: RuntimeWarning: overflow encountered in divide\n",
      "  pts4D /= pts4D[-1, :]\n"
     ]
    }
   ],
   "source": [
    "# Choose matrix that has all points in front and minimizes reprojection loss\n",
    "\n",
    "def triangulate(pts1, pts2, P1, P2):\n",
    "    # Calculate 3D point\n",
    "    pts4D = np.zeros((4, pts1.shape[1]))\n",
    "    pts4D = cv2.triangulatePoints(P1, P2, pts1, pts2, pts4D)\n",
    "    pts4D /= pts4D[-1, :]\n",
    "\n",
    "    # Calculate reprojection error\n",
    "    # First, get reprojections\n",
    "    pts1_reproj = P1 @ pts4D\n",
    "    pts2_reproj = P2 @ pts4D\n",
    "\n",
    "    pts1_reproj /= pts1_reproj[-1, :]\n",
    "    pts2_reproj /= pts2_reproj[-1, :]\n",
    "\n",
    "    # Second, homogenize every point to compare with the reprojection\n",
    "    # pts1 (2xN)\n",
    "    pts1_homo = np.concatenate((pts1, np.ones((1, pts1.shape[1]))), axis=0)\n",
    "    pts2_homo = np.concatenate((pts2, np.ones((1, pts2.shape[1]))), axis=0)\n",
    "\n",
    "    err1 = np.sum(np.square(pts1_reproj - pts1_homo))\n",
    "    err2 = np.sum(np.square(pts2_reproj - pts2_homo))\n",
    "\n",
    "    err = err1 + err2\n",
    "    return pts4D[:3, :], err\n",
    "\n",
    "for i in range(rot_trans_list.shape[0]):\n",
    "    RT = rot_trans_list[i]\n",
    "    best_RT = np.zeros((3, 4))\n",
    "    best_error = np.finfo('float').max\n",
    "    for j in range(RTs.shape[2]):\n",
    "        RT = RTs[:, :, j]\n",
    "        P2_tmp = K @ RT\n",
    "        pts1 = np.array([kp[i][m.queryIdx].pt for m in matches[i]]).astype('float').T\n",
    "        pts2 = np.array([kp[i+1][m.trainIdx].pt for m in matches[i]]).astype('float').T\n",
    "        X, err = triangulate(pts1, pts2, Ps[i], P2_tmp)\n",
    "        if err < best_error and np.all(X[-1, :] >= 0):\n",
    "            best_error = err\n",
    "            P = X\n",
    "            Ps[i+1] = P2_tmp\n",
    "            best_RT = RT\n",
    "\n",
    "Ps = np.array(Ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
